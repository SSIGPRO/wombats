{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb162f59-5224-454f-9de7-7e2db3ffe6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import io\n",
    "import wfdb\n",
    "from scipy import interpolate\n",
    "from bridge_data_utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf55d04-bb6b-4b00-ab90-922886289f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_normal_ECG(n=256, SNRdB=10, N_test=10_000, val_frac=0.1):\n",
    "    folder = '/srv/penny/datasets/synth_ecg'\n",
    "    name = 'ecgSyn_n512_Ny256_(HR 80 100).mat'\n",
    "    path = os.path.join(folder, name)\n",
    "    X =  io.loadmat(path)['sigs'].T\n",
    "    # standardize data\n",
    "    X = (X - np.mean(X))/X.std()\n",
    "    # add noise guaranteeing a certain SNR\n",
    "    if SNRdB is not None:\n",
    "        X = X + np.random.randn(*X.shape)*10**(-SNRdB/20)\n",
    "    \n",
    "    X_train_ = X[:-N_test, 0:n]\n",
    "    X_test = X[-N_test:, 0:n]\n",
    "        \n",
    "    # shuffle the training set\n",
    "    # and split between training and validation\n",
    "    indexes = np.random.permutation(len(X_train))\n",
    "    N_val = int(len(X_train_)*val_frac)\n",
    "    X_train = X_train_[indexes[:-N_val]]\n",
    "    X_val = X_train_[indexes[-N_val:]]\n",
    "    \n",
    "    return X_train, X_val, X_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8131f859-8914-40bd-8f11-2c7ea53b5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_anomalous_ECG(n=256, fs_train=256, patient ='101'):\n",
    "    if 'ecg-anomalies' not in os.listdir():\n",
    "        os.mkdir('ecg-anomalies')\n",
    "    # download MIT database and save in 'ecg-anomalies'\n",
    "    wfdb.dl_database('mitdb', 'ecg-anomalies', records=[patient])\n",
    "    # retrieve patient's record\n",
    "    record = wfdb.rdrecord(f'ecg-anomalies/{patient}')\n",
    "    df = record.to_dataframe()\n",
    "    \n",
    "    # label samples in the time series\n",
    "    annotations = wfdb.rdann(patient, 'atr', pn_dir='mitdb')\n",
    "    labels_ko = annotations.symbol\n",
    "    samples = annotations.sample\n",
    "    labels = np.array(len(df)*['K'])\n",
    "    labels[samples] = labels_ko\n",
    "    labels = pd.Series(index=df.index, data=labels)\n",
    "    \n",
    "    # resample the time series\n",
    "    fs = record.fs\n",
    "    N = fs_train / fs # sampling factor\n",
    "    time_series = df['MLII'].values\n",
    "    t = np.linspace(0, 1, len(time_series))\n",
    "    spline = interpolate.splrep(t, time_series, s=0, k=5)\n",
    "    tt = np.linspace(0, 1, int(N * len(time_series)))\n",
    "    time_series_unders = interpolate.splev(tt, spline, der=0)\n",
    "    time_series_unders = time_series_unders[:(len(time_series_unders)//(2*n))*2*n]\n",
    "    \n",
    "    # create a new time index\n",
    "    tw = pd.Timedelta(1/fs_train, 's')\n",
    "    index = pd.TimedeltaIndex([df.index[0] + i*tw for i in np.arange(len(time_series_unders))])\n",
    "    \n",
    "    # standardize \n",
    "    time_series_unders_std = (time_series_unders - time_series_unders.mean()) / time_series_unders.std()\n",
    "    time_series_unders_std = time_series_unders_std[:(len(time_series_unders_std)//(2*n))*2*n]\n",
    "\n",
    "    time_series_unders = pd.DataFrame(index=index, data=time_series_unders)\n",
    "    \n",
    "    # window the time series\n",
    "    instances = time_series_unders_std.reshape(-1, n)\n",
    "    index = index.floor(tw)[::n]\n",
    "    index = index[:len(instances)] + tw/2    \n",
    "    instances = pd.DataFrame(index=index, data=instances)\n",
    "    \n",
    "    return time_series_unders, instances, labels\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b166c2-3417-4b15-9f48-b08528d9f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bridge_data(sensor='1D30', n=100, train_period=None, test_period=None):\n",
    "    # setup data connection\n",
    "    lib_path = os.path.join('/srv/penny/RFI/roccaprebalza/scripts/old')\n",
    "    data_path = os.path.join('/srv/penny/RFI/roccaprebalza/rawdata')\n",
    "    sys.path.append(lib_path)\n",
    "    from localdata import DataConnection\n",
    "    rpbz = DataConnection(os.path.join(lib_path, 'index_fixed2.parquet'), data_path)\n",
    "    \n",
    "    # sampling frequency\n",
    "    fs = rpbz.info['fs']\n",
    "    \n",
    "    #scaling mode\n",
    "    mode = 'channel' #channel # all\n",
    "    # axes\n",
    "    channels = ['x', 'y', 'z']\n",
    "    \n",
    "    channel = '_'.join([ch for ch in channels])\n",
    "    \n",
    "    # load train data\n",
    "    start_time = pd.Timestamp(train_period[0], tz='UTC')\n",
    "    end_time = pd.Timestamp(train_period[1], tz='UTC')\n",
    "    time_series_train = rpbz.getData([sensor], start_time, end_time, drop_sync=True).astype(float)\n",
    "    \n",
    "    # load test data\n",
    "    start_time = pd.Timestamp(test_period[0], tz='UTC')\n",
    "    end_time = pd.Timestamp(test_period[1], tz='UTC')\n",
    "    time_series_test = rpbz.getData([sensor], start_time, end_time, drop_sync=True).astype(float)\n",
    "    \n",
    "    # process data\n",
    "    threshold = None\n",
    "    train_data_processed, threshold, scaler = preprocess(time_series_train, n, fs, threshold, None, mode)\n",
    "    print(threshold)\n",
    "    # process test data accoding to train data\n",
    "    test_data_processed, _, _, = preprocess(time_series_test, n, fs, threshold, scaler, mode)\n",
    "    \n",
    "    return train_data_processed, test_data_processed, time_series_train, time_series_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3d9b389-c259-4352-ae90-19077d09c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_normal_bridge(sensor='1D30', n=100, channel='x', N_test=10_000, val_frac=0.1):\n",
    "    # definition of the time periods on which train and evaluate PCA\n",
    "    train_period = ['2017-10-02 00:00:00', '2017-10-08 23:59:59']\n",
    "    test_period = ['2017-10-09 00:00:00', '2017-10-15 23:59:59']\n",
    "    train_data, test_data, _, _ = load_bridge_data(sensor, n, train_period, test_period)\n",
    "    \n",
    "    N_train = len(train_data)\n",
    "    X_train_ = train_data[channel].values\n",
    "    indexes = np.random.permutation(N_train)\n",
    "    N_val = int(N_train*val_frac)\n",
    "    X_train = X_train_[indexes[:N_val]]\n",
    "    X_val = X_train_[indexes[N_val:]]\n",
    "    \n",
    "    X_test = test_data[channel].values\n",
    "    indexes = np.random.permutation(len(X_test))\n",
    "    X_test = X_test[indexes]\n",
    "    X_test = X_test[:N_test]\n",
    "    \n",
    "    return X_train, X_val, X_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f636714d-9487-47ad-8adc-fa177d64ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "def load_anomalous_bridge(sensor='1D30', n=100, channel='x', N_test=10_000, val_frac=0.1):\n",
    "    # definition of the time periods on which train and evaluate PCA\n",
    "    train_period = ['2017-10-02 00:00:00', '2017-10-08 23:59:59']\n",
    "    test_period = ['2017-11-19 00:00:00', '2017-11-19 23:59:59']\n",
    "    train_data, test_data, _, _ = load_bridge_data(sensor, n, train_period, test_period)\n",
    "    \n",
    "    N_train = len(train_data)\n",
    "    X_train_ = train_data[channel].values\n",
    "    indexes = np.random.permutation(N_train)\n",
    "    N_val = int(N_train*val_frac)\n",
    "    X_train = X_train_[indexes[:N_val]]\n",
    "    X_val = X_train_[indexes[N_val:]]\n",
    "    \n",
    "    X_test = test_data[channel].values\n",
    "    indexes = np.random.permutation(len(X_test))\n",
    "    X_test = X_test[indexes]\n",
    "    X_test = X_test[:N_test]\n",
    "    \n",
    "    return X_train, X_val, X_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ae3b37d-49da-4600-8302-33e354230d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading /srv/penny/RFI/roccaprebalza/scripts/old/index_fixed2.parquet ... OK\n",
      "18526.91380556385\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test = load_normal_bridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5a0dc-4b29-4ef0-8aa4-b2c46074d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_period = ['2017-11-19 00:00:00', '2017-11-19 23:59:59']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
